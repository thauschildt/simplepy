import 'lexer.dart';
import 'ast_nodes.dart';

/// An exception thrown when the [Parser] encounters a syntax error
/// that violates the grammar rules of the language subset.
///
/// It includes the [token] at or near which the error occurred (providing location
/// information) and a descriptive [message] about the specific parsing failure.
class ParseError implements Exception {
  final Token token;
  final String message;
  ParseError(this.token, this.message);
  @override
  String toString() =>
      '[line ${token.line}, col ${token.column}] Parse Error at \'${token.lexeme}\': $message';
}

/// Parses a stream of [Token]s (produced by a [Lexer]) into an
/// Abstract Syntax Tree (AST) consisting of [Stmt] and [Expr] nodes.
///
/// This parser uses a recursive descent strategy, where each grammar rule
/// typically corresponds to a method in the class. It handles operator precedence,
/// control flow structures (if, while, for), function definitions, calls,
/// assignments, and various expressions based on the Python subset grammar.
///
/// The parser also includes error handling and synchronization capabilities
/// to attempt recovery after a syntax error and report multiple errors in one pass.
class Parser {
  /// The list of tokens provided by the [Lexer].
  final List<Token> tokens;

  /// An optional callback function to report error messages during parsing.
  /// Used primarily when [synchronize] is called.
  Function(String)? errorCallback;

  /// The index of the next token to be consumed from the [tokens] list.
  int current = 0;

  /// Creates a new [Parser] instance.
  ///
  /// Takes the [tokens] list generated by the [Lexer] as input.
  /// An optional [errorCallback] can be provided to receive error messages
  /// encountered during parsing, particularly during error recovery.
  Parser(this.tokens, [this.errorCallback]);

  /// Parses the entire list of [tokens] and returns a list of top-level [Stmt] nodes,
  /// representing the program's structure.
  ///
  /// This is the main entry point for the parser. It iteratively calls [declaration]
  /// to parse each top-level statement or definition until the end of the token stream
  /// ([TokenType.EOF]) is reached. It handles newlines between top-level statements.
  ///
  /// If a [ParseError] occurs, it attempts to recover using [synchronize] and continues
  /// parsing to find subsequent errors. Error messages are typically printed via
  /// the [errorCallback] or caught exception handlers.
  List<Stmt> parse() {
    List<Stmt> statements = [];
    while (!isAtEnd()) {
      // Skip leading newlines between statements at the top level
      while (match([TokenType.NEWLINE])) { /* consume */ }
      if (isAtEnd()) break;
      try {
        Stmt? stmt = declaration();
        if (stmt != null) {
          statements.add(stmt);
        } else if (!isAtEnd()) {
          // If declaration returned null but we're not at EOF, it means an error occurred
          // and synchronize was called. We should continue parsing the next statement.
          // Avoid adding nulls directly.
          synchronize(); // Ensure we are at a recovery point
        }
      } on ParseError catch (e) {
        print(e);
        synchronize();
      }
      // Ensure we consume trailing newlines after a statement/block
      while (match([TokenType.NEWLINE])) {
        /* consume */
      }
    }
    // Filter out nulls which might occur due to synchronization (although we try to avoid adding them)
    // return statements.where((s) => s != null).cast<Stmt>().toList();
    return statements; // Return the list directly
  }

  // --- Grammar Rule Methods ---

  /// Parses a declaration, which can be a function definition or any other statement.
  /// declaration ::= classDecl | functionDecl | statement ;
  Stmt? declaration() {
    try {
      if (match([TokenType.CLASS])) return classDeclaration();
      if (match([TokenType.DEF])) return functionDeclaration("function");
      return statement();
    } catch (e) {
      // If a ParseError occurs within a production rule, it's caught here
      // (or by the main loop if it bubbles up). Call synchronize.
      print(e); // Error already printed by main loop or specific rule
      synchronize();
      return null; // Indicate failure to the main loop
    }
  }

  /// Parses a class definition.
  /// classDecl ::= "class" IDENTIFIER ( "(" IDENTIFIER ")" )? ":" block ;
  /// Note: block for classes currently only contains methods (DEF).
  Stmt classDeclaration() {
    Token name = consume(TokenType.IDENTIFIER, "Expect class name.");
    VariableExpr? superclass;
    if (match([TokenType.LEFT_PAREN])) {
      Token superclassName = consume(TokenType.IDENTIFIER, "Expect superclass name.");
      superclass = VariableExpr(superclassName);
      consume(TokenType.RIGHT_PAREN, "Expect ')' after superclass name.");
    }
    consume(TokenType.COLON, "Expect ':' after class name or superclass.");
    consume(TokenType.NEWLINE, "Expect newline after ':'.");
    consume(TokenType.INDENT, "Expect indent after ':'.");
    List<FunctionStmt> methods = [];
    while (!check(TokenType.DEDENT) && !isAtEnd()) {
      // Skip blank lines within the class body
      while(match([TokenType.NEWLINE])) {/* consume */}
      if (check(TokenType.DEDENT) || isAtEnd()) break;
      if (match([TokenType.DEF])) {
        // Pass "method" to indicate context if needed by functionDeclaration
        methods.add(functionDeclaration("method") as FunctionStmt);
      }  else if (match([TokenType.PASS])) {
        if (!check(TokenType.DEDENT)) {
          match([TokenType.NEWLINE]);
        }
        continue;
      } else {
        throw error(peek(),"Only method definitions (def) or 'pass' are allowed inside a class body for now.");
      }
      // Consume optional newline before next method or dedent
      if (!check(TokenType.DEDENT)) {
        match([TokenType.NEWLINE]);
      }
    }
    consume(TokenType.DEDENT, "Expect dedent to close class body.");
    return ClassStmt(name, superclass, methods);
  }

  /// Parses a function definition.
  /// functionDecl ::= "def" IDENTIFIER "(" parameters? ")" ":" block ;
  /// parameters   ::= parameter ("," parameter)* ;
  /// parameter    ::= IDENTIFIER ("=" expression)? | "*" IDENTIFIER | "**" IDENTIFIER ;
  Stmt functionDeclaration(String kind) {
    Token name = consume(TokenType.IDENTIFIER, "Expect $kind name.");
    consume(TokenType.LEFT_PAREN, "Expect '(' after $kind name.");

    List<Parameter> parameters = [];
    bool parsingOptional = false; // True once '=' is seen
    bool parsingArgs = false; // True once '*' is seen
    bool parsingKwargs = false; // True once '**' is seen

    if (!check(TokenType.RIGHT_PAREN)) {
      do {
        if (parameters.length >= 255) {
          error(peek(), "Can't have more than 255 parameters.");
        }

        if (match([TokenType.STAR_STAR])) {
          // **kwargs
          if (parsingKwargs) {
            error(previous(), "Multiple **kwargs parameters are not allowed.");
          }
          if (parsingArgs) {
            error(
              previous(),
              "Cannot have **kwargs after *args.",
            ); // Correction: Should be allowed
          }
          // Python allows **kwargs anytime after non-keywords.
          // Let's enforce it comes last for simplicity.
          if (parameters.any((p) => p is! StarStarKwargsParameter)) {
            // Check if *args already exists
            if (parameters.any((p) => p is StarArgsParameter)) {
              // Allow **kwargs after *args
            } else if (parameters.any(
              (p) => p is OptionalParameter || p is RequiredParameter,
            )) {
              // Allow **kwargs after optional/required
            }
            // Simplified: Ensure it's the last thing defined
            bool onlyKwargsLeft = parameters.every(
              (p) => p is StarStarKwargsParameter,
            );
            if (!onlyKwargsLeft && parameters.isNotEmpty) {
              // This logic is tricky, Python's rules are complex.
              // Let's enforce **kwargs is the very last parameter type defined.
              if (parsingArgs ||
                  parsingOptional ||
                  parameters.any((p) => p is! StarStarKwargsParameter)) {
                //error(previous(), "**kwargs must be the last parameter.");
                // Allow it, but set flag
              }
            }
          }

          parsingKwargs = true;
          parsingOptional = false; // Can't have regular params after **
          parsingArgs =
              false; // Can't have *args after ** (though already disallowed)

          Token paramName = consume(
            TokenType.IDENTIFIER,
            "Expect identifier after '**'.",
          );
          parameters.add(StarStarKwargsParameter(paramName));
        } else if (match([TokenType.STAR])) {
          // *args
          if (parsingArgs) {
            error(previous(), "Multiple *args parameters are not allowed.");
          }
          if (parsingKwargs) {
            error(previous(), "Cannot have *args after **kwargs.");
          }

          // Simplified: Ensure *args comes before **kwargs and after regular args
          if (parameters.any((p) => p is StarStarKwargsParameter)) {
            error(previous(), "*args must come before **kwargs.");
          }

          parsingArgs = true;
          parsingOptional =
              false; // Can't have regular optional params after *args

          Token paramName = consume(
            TokenType.IDENTIFIER,
            "Expect identifier after '*'.",
          );
          parameters.add(StarArgsParameter(paramName));
        } else {
          // Required or Optional
          if (parsingArgs) {
            error(peek(), "Positional/optional parameter cannot follow *args.");
          }
          if (parsingKwargs) {
            error(peek(), "Positional/optional parameter cannot follow **kwargs.");
          }

          Token paramName = consume(TokenType.IDENTIFIER, "Expect parameter name.");

          if (match([TokenType.EQUAL])) {
            // Optional parameter
            parsingOptional = true; // Mark that we've seen an optional param
            Expr defaultValue = expression(); // Parse the default value
            parameters.add(OptionalParameter(paramName, defaultValue));
          } else {
            // Required parameter
            if (parsingOptional) {
              // Python allows required after optional IF using * separator,
              // but standard args must have required before optional.
              error(
                paramName,
                "Non-default argument follows default argument.",
              );
            }
            parameters.add(RequiredParameter(paramName));
          }
        }
      } while (match([TokenType.COMMA]));
    }

    consume(TokenType.RIGHT_PAREN, "Expect ')' after parameters.");
    consume(TokenType.COLON, "Expect ':' before $kind body.");

    List<Stmt> body;
    if (peek().type == TokenType.NEWLINE) {
      body = block(); // standard function block
    } else {
      // single-line function def
      body = [statement()];
      if (peek().type != TokenType.NEWLINE && !isAtEnd()) {
        throw error(peek(), "invalid syntax");
      }
    }
    return FunctionStmt(name, parameters, body); // Pass the new list
  }

  /// Parses a statement.
  /// statement ::= ifStmt | returnStmt | whileStmt | forStmt | passStmt
  ///             | breakStmt | continueStmt | exprStmt ;
  Stmt statement() {
    if (match([TokenType.IF])) return ifStatement();
    if (match([TokenType.RETURN])) return returnStatement();
    if (match([TokenType.WHILE])) return whileStatement();
    if (match([TokenType.FOR])) return forStatement();
    if (match([TokenType.PASS])) return passStatement();
    if (match([TokenType.BREAK])) return breakStatement();
    if (match([TokenType.CONTINUE])) return continueStatement();
    if (match([TokenType.GLOBAL])) return globalStatement();
    if (match([TokenType.NONLOCAL])) return nonlocalStatement(); 
    // Note: Block statements are handled within constructs like if/while/for/def
    return expressionStatement();
  }

  /// Parses a block of statements, typically following a colon (:).
  /// Expects a [TokenType.NEWLINE], followed by an [TokenType.INDENT], then a sequence
  /// of statements, and finally a [TokenType.DEDENT]. Handles nested blocks.
  /// block ::= NEWLINE INDENT statement* DEDENT ;
  List<Stmt> block() {
    // Expect NEWLINE then INDENT after the ':' that triggers the block
    consume(TokenType.NEWLINE, "Expect newline after ':'.");
    consume(TokenType.INDENT, "Expect indent after ':'.");

    List<Stmt> statements = [];
    while (!check(TokenType.DEDENT) && !isAtEnd()) {
      // Skip potential multiple newlines within the block
      while (match([TokenType.NEWLINE])) {
        /* consume */
      }
      if (check(TokenType.DEDENT) || isAtEnd()) {
        break; // Re-check after skipping newlines
      }

      var stmt = declaration(); // Allow function defs inside blocks too
      if (stmt != null) {
        statements.add(stmt);
      } else if (!isAtEnd() && !check(TokenType.DEDENT)) {
        // Error occurred and was synchronized, but we are not at dedent yet.
        // Avoid infinite loop if synchronize didn't advance properly.
        synchronize(); // Try synchronizing again
      }
      // Don't require newline strictly *after* every statement if the next is dedent
      // Consume optional newline ONLY if the next token isn't DEDENT
      if (!check(TokenType.DEDENT)) {
        match([TokenType.NEWLINE]); // Consume optional single newline
      }
    }
    consume(TokenType.DEDENT, "Expect dedent to close block.");
    return statements;
  }

  /// Parses an if-elif-else statement.
  /// ifStmt ::= "if" expression ":" block
  ///            ( "elif" expression ":" block )*
  ///            ( "else" ":" block )? ;
  Stmt ifStatement() {
    Expr condition = expression();
    consume(TokenType.COLON, "Expect ':' after if condition.");
    Stmt thenBranch;
    if (peek().type == TokenType.NEWLINE) {
      thenBranch = BlockStmt(block()); // standard block
    } else {
      thenBranch = BlockStmt([statement()]); // single-line statement as block with one statement
      if (peek().type != TokenType.NEWLINE && !isAtEnd()) {
        throw error(peek(), "invalid syntax.");
      }
      if (peek().type == TokenType.NEWLINE) {
        consume(TokenType.NEWLINE, 'invalid syntax');
      }
    }
    List<ElifBranch> elifBranches = [];
    while (match([TokenType.ELIF])) {
      Expr elifCondition = expression();
      consume(TokenType.COLON, "Expect ':' after elif condition.");
      Stmt elifThenBranch;
      if (peek().type == TokenType.NEWLINE) {
        elifThenBranch = BlockStmt(block());
      } else {
        elifThenBranch = BlockStmt([statement()]);
        if (peek().type != TokenType.NEWLINE && !isAtEnd()) {
          throw error(peek(), "invalid syntax");
        }
        if (peek().type == TokenType.NEWLINE) {
          consume(TokenType.NEWLINE, 'invalid syntax');
        }
      }
      elifBranches.add(ElifBranch(elifCondition, elifThenBranch));
    }

    Stmt? elseBranch;
    if (match([TokenType.ELSE])) {
      consume(TokenType.COLON, "Expect ':' after else.");
      if (peek().type == TokenType.NEWLINE) {
        elseBranch = BlockStmt(block());
      } else {
        elseBranch = BlockStmt([statement()]);
        if (peek().type != TokenType.NEWLINE && !isAtEnd()) {
          throw error(peek(), "invalid syntax");
        }
      }
    }

    // Consume trailing newline automatically handled by main parsing loop or block parsing
    return IfStmt(condition, thenBranch, elifBranches, elseBranch);
  }

  /// Parses a return statement.
  /// returnStmt ::= "return" expression? ;
  Stmt returnStatement() {
    Token keyword = previous();
    Expr? value;
    // Return value is optional. Check if the line ends or block dedents.
    if (!check(TokenType.NEWLINE) &&
        !check(TokenType.EOF) &&
        !check(TokenType.DEDENT)) {
      value = expression();
    }
    // Consume trailing newline automatically handled by block/main loop
    return ReturnStmt(keyword, value);
  }

  /// Parses a while loop statement.
  /// whileStmt ::= "while" expression ":" block ;
  Stmt whileStatement() {
    Expr condition = expression();
    consume(TokenType.COLON, "Expect ':' after while condition.");
    Stmt body;
    if (peek().type == TokenType.NEWLINE) {
      body = BlockStmt(block()); // standard block
    } else {
      // single-line body
      body = BlockStmt([statement()]);
      if (peek().type != TokenType.NEWLINE && !isAtEnd()) {
        throw error(peek(), "invalid syntax");
      }
    }
    return WhileStmt(condition, body);
  }

  /// Parses a for loop statement.
  /// forStmt ::= "for" IDENTIFIER "in" expression ":" block ;
  Stmt forStatement() {
    Token variable = consume(
      TokenType.IDENTIFIER,
      "Expect variable name after 'for'.",
    );
    consume(TokenType.IN, "Expect 'in' after variable.");
    Expr iterable = expression(); // e.g., range(5) or a list variable
    consume(TokenType.COLON, "Expect ':' after iterable.");
    Stmt body;
    if (peek().type == TokenType.NEWLINE) {
      body = BlockStmt(block()); // standard block
    } else {
      // single-line body
      body = BlockStmt([statement()]);
      if (peek().type != TokenType.NEWLINE && !isAtEnd()) {
        throw error(peek(), "invalid syntax");
      }
    }
    return ForStmt(variable, iterable, body);
  }

   /// Parses a pass statement.
  /// passStmt ::= "pass" ;
  Stmt passStatement() {
    return PassStmt(previous());
  }

  /// Parses a break statement.
  /// breakStmt ::= "break" ;
  Stmt breakStatement() {
    return BreakStmt(previous());
  }

  /// Parses a continue statement.
  /// continueStmt ::= "continue" ;
  Stmt continueStatement() {
    return ContinueStmt(previous());
  }

  /// Parses a global statement.
  /// globalStmt ::= "global" IDENTIFIER ("," IDENTIFIER)* ;
  Stmt globalStatement() {
    List<Token> names = [];
    do {
      names.add(consume(TokenType.IDENTIFIER, "Expect variable name after 'global'."));
    } while (match([TokenType.COMMA]));
    consume(TokenType.NEWLINE, "Expect newline after 'global' statement.");
    return GlobalStmt(names);
  }

  /// Parses a nonlocal statement.
  /// nonlocalStmt ::= "nonlocal" IDENTIFIER ("," IDENTIFIER)* ;
  Stmt nonlocalStatement() {
    List<Token> names = [];
    do {
      names.add(consume(TokenType.IDENTIFIER, "Expect variable name after 'nonlocal'."));
    } while (match([TokenType.COMMA]));
    consume(TokenType.NEWLINE, "Expect newline after 'nonlocal' statement.");
    return NonlocalStmt(names);
  }

  /// Parses an expression statement.
  /// exprStmt ::= expression ;
  Stmt expressionStatement() {
    Expr expr = expression();
    // Consume trailing newline automatically handled by block/main loop
    return ExpressionStmt(expr);
  }

  /// Parses an expression (entry point, lowest precedence).
  /// expression ::= assignment ;
  Expr expression() {
    return assignment();
  }

  /// Parses an assignment expression (including augmented assignment).
  /// assignment ::= ( target (augAssignOp | "=") )? logicOr ;
  /// target     ::= IDENTIFIER | callOrGet "[" expression "]" ; // Simplified target
  /// augAssignOp::= "+=" | "-=" | "*=" | "/=" | "//=" | "%=" | "**=" | "&=" | "|=" | "^=" | "<<=" | ">>=" ;
  Expr assignment() {
    Expr expr = logicOr(); // Start with lowest precedence (or maybe ternary later)

    if (match([
      TokenType.PLUS_EQUAL, TokenType.MINUS_EQUAL, TokenType.STAR_EQUAL, TokenType.SLASH_EQUAL,
      TokenType.PERCENT_EQUAL, TokenType.STAR_STAR_EQUAL, TokenType.SLASH_SLASH_EQUAL,
      TokenType.AMPERSAND_EQUAL, TokenType.PIPE_EQUAL, TokenType.CARET_EQUAL,
      TokenType.LEFT_SHIFT_EQUAL, TokenType.RIGHT_SHIFT_EQUAL,
    ])) {
      Token operator = previous();
      Expr value = assignment();
      if (expr is VariableExpr || expr is AttributeGetExpr || expr is IndexGetExpr) {
        return AugAssignExpr(expr, operator, value);
      }
      error(operator, "Invalid assignment target.");
    } else if (match([TokenType.EQUAL])) {
      Token equals = previous();
      Expr value = assignment(); // Right-associative
      if (expr is VariableExpr) {
        Token name = expr.name;
        return AssignExpr(name, value);
      } else if (expr is IndexGetExpr) {
        return IndexSetExpr(expr.object, expr.index, value, expr.bracket);
      } else if (expr is AttributeGetExpr) {
        return AttributeSetExpr(expr.object, expr.name, value);
      }
      error(equals, "Invalid assignment target.");
    }
    return expr; // Not an assignment, just return the parsed expression
  }

  /// Parses logical OR expressions. ('or')
  /// logicOr ::= logicAnd ( "or" logicAnd )* ;
  Expr logicOr() {
    Expr expr = logicAnd();
    while (match([TokenType.OR])) {
      Token operator = previous();
      Expr right = logicAnd();
      expr = LogicalExpr(expr, operator, right);
    }
    return expr;
  }

  /// Parses logical AND expressions. ('and')
  /// logicAnd ::= negation ( "and" negation )* ;
  Expr logicAnd() {
    Expr expr = negation();
    while (match([TokenType.AND])) {
      Token operator = previous();
      Expr right = negation();
      expr = LogicalExpr(expr, operator, right);
    }
    return expr;
  }

  /// Parses logical NOT expressions. ('not')
  /// negation ::= ( "not" negation ) | comparison ;
  Expr negation() {
    if (match([TokenType.NOT])) {
      Token operator = previous();
      Expr operand = negation();
      return UnaryExpr(operator, operand);
    }
    return comparison();
  }

  /// Parses comparison expressions. (==, !=, <, <=, >, >=)
  /// comparison ::= bitwiseOr ( compOp bitwiseOr )* ;
  /// compOp     ::= "==" | "!=" | "<" | "<=" | ">" | ">=" ;
  // TODO: Add "in", "not in", "is", "is not"
  Expr comparison() {
    Expr expr = lambda();
    // Add 'in' operator here? Or handle separately. Let's keep it simple for now.
    while (match([
      TokenType.GREATER, TokenType.GREATER_EQUAL, TokenType.LESS, TokenType.LESS_EQUAL,
      TokenType.BANG_EQUAL, TokenType.EQUAL_EQUAL, TokenType.IN,
    ])) {
      Token operator = previous();
      Expr right = lambda();
      expr = BinaryExpr(expr, operator, right);
    }
    return expr;
  }

  /// Parses a lambda expression or delegates to the next precedence level.
  /// lambdaExpr ::= "lambda" parameters? ":" expression ;
  Expr lambda() {
    if (match([TokenType.LAMBDA])) {
      Token keyword = previous();
      // Parse parameters directly (no parentheses needed for lambda)
      List<Parameter> parameters = _parseLambdaParameters(); // Need specific parameter parser
      consume(TokenType.COLON, "Expect ':' after lambda parameters.");
      Expr body = expression(); // Parse the single expression body
      return LambdaExpr(keyword, parameters, body);
    }
    // If not a lambda, continue down the precedence chain
    return bitwiseOr();
  }

  /// Helper method to parse the parameter list for a lambda expression (no parens).
  /// Stops parsing at the COLON.
  List<Parameter> _parseLambdaParameters() {
    List<Parameter> parameters = [];
    // Check if the very next token is COLON (lambda with no params)
    if (check(TokenType.COLON)) {
      return parameters; // Empty parameter list
    }
    // Logic similar to parsing parameters in functionDeclaration(), but stops at COLON instead of RIGHT_PAREN
    bool parsingOptional = false;
    // TODO: check correct order of positional, optional, *args, **kwargs
    do { // Use do-while because we checked COLON already, so at least one param expected if not empty
      if (parameters.length >= 255) throw error(peek(), "Can't have more than 255 parameters.");
      if (match([TokenType.STAR_STAR])) { // **kwargs
        parsingOptional = false;
        Token paramName = consume(TokenType.IDENTIFIER, "Expect identifier after '**'.");
        parameters.add(StarStarKwargsParameter(paramName));
      } else if (match([TokenType.STAR])) { // *args
        parsingOptional = false;
        Token paramName = consume(TokenType.IDENTIFIER, "Expect identifier after '*'.");
        parameters.add(StarArgsParameter(paramName));
      } else { // Required or Optional
        Token paramName = consume(TokenType.IDENTIFIER, "Expect parameter name.");
        if (match([TokenType.EQUAL])) { // Optional
          parsingOptional = true;
          Expr defaultValue = expression();
          parameters.add(OptionalParameter(paramName, defaultValue));
        } else { // Required
          if (parsingOptional) throw error(paramName, "Non-default argument follows default argument.");
          parameters.add(RequiredParameter(paramName));
        }
      }
      // Continue if a comma follows, otherwise break (expecting COLON next)
    } while (match([TokenType.COMMA]));
    // After the loop, the next token MUST be COLON (consumed by the caller)
    return parameters;
  }

  /// Parses bitwise OR expressions. ('|')
  /// bitwiseOr ::= bitwiseXor ( "|" bitwiseXor )* ;
  Expr bitwiseOr() {
    Expr expr = bitwiseXor();
    while (match([TokenType.PIPE])) {
      Token operator = previous();
      Expr right = bitwiseXor();
      expr = BinaryExpr(expr, operator, right);
    }
    return expr;
  }

  /// Parses bitwise XOR expressions. ('^')
  /// bitwiseXor ::= bitwiseAnd ( "^" bitwiseAnd )* ;
  Expr bitwiseXor() {
    Expr expr = bitwiseAnd();
    while (match([TokenType.CARET])) {
      Token operator = previous();
      Expr right = bitwiseAnd();
      expr = BinaryExpr(expr, operator, right);
    }
    return expr;
  }

  /// Parses bitwise AND expressions. ('&')
  /// bitwiseAnd ::= shift ( "&" shift )* ;
  Expr bitwiseAnd() {
    Expr expr = shift();
    while (match([TokenType.AMPERSAND])) {
      Token operator = previous();
      Expr right = shift();
      expr = BinaryExpr(expr, operator, right);
    }
    return expr;
  }

  /// Parses bitwise shift expressions. ('<<', '>>')
  /// shift ::= addsub ( ("<<" | ">>") addsub )* ;
  Expr shift() { 
    Expr expr = addsub();
    while (match([TokenType.LEFT_SHIFT, TokenType.RIGHT_SHIFT])) {
      Token operator = previous();
      Expr right = addsub();
      expr = BinaryExpr(expr, operator, right);
    }
    return expr;
  }

  /// Parses addition and subtraction expressions. ('+', '-')
  /// addsub ::= factor ( ("+" | "-") factor )* ;
  Expr addsub() {
    Expr expr = factor();
    while (match([TokenType.MINUS, TokenType.PLUS])) {
      Token operator = previous();
      Expr right = factor();
      expr = BinaryExpr(expr, operator, right);
    }
    return expr;
  }

  /// Parses multiplication, division, floor division, and modulo expressions. ('*', '/', '//', '%')
  /// factor ::= unary ( ("*" | "/" | "//" | "%") unary )* ;
  Expr factor() {
    Expr expr = unary();
    while (match([
      TokenType.SLASH, TokenType.SLASH_SLASH,
      TokenType.STAR, TokenType.PERCENT,
    ])) {
      Token operator = previous();
      Expr right = unary();
      expr = BinaryExpr(expr, operator, right);
    }
    return expr;
  }

  /// Parses unary expressions. ('-', '+', '~')
  /// Note: 'not' handled in `negation`.
  /// unary ::= ("+" | "-" | "~") unary | exponentiation ;
  Expr unary() {
    if (match([TokenType.MINUS, TokenType.PLUS, TokenType.TILDE])) {
      Token operator = previous();
      Expr operand = unary(); // recursive call to allow for e.g. '--2'
      return UnaryExpr(operator, operand);
    }
    return exponentiation();
  }

  /// Parses exponentiation expressions. ('**') Right-associative.
  /// exponentiation ::= call ( "**" unary )? ; // Right operand has higher precedence (unary)
  Expr exponentiation() {
    Expr expr = call();
    if (match([TokenType.STAR_STAR])) {
      Token operator = previous();
      Expr right = unary();
      return BinaryExpr(expr, operator, right);
    }
    return expr;
  }

  /// Parses function calls and indexing/subscription expressions. Handles chaining like `f()[0]`.
  /// call ::= primary ( "(" arguments? ")" | "[" expression "]" )* ;
  Expr call() {
    Expr expr = primary(); // Parse the base callable/object
    while (true) {
    // Allow chaining: func()(...) or list[i](...)
      if (match([TokenType.LEFT_PAREN])) {
        expr = finishCall(expr); // expr becomes the CallExpr node
      } else if (match([TokenType.LEFT_BRACKET])) {
        expr = finishIndex(expr); // expr becomes the GetExpr node
      }  else if (match([TokenType.DOT])) {
        Token name = consume(TokenType.IDENTIFIER, "Expect property name after '.'.");
        expr = AttributeGetExpr(expr, name);
      }
      else {
        break; // No more calls, indexing, or dot
      }
    }
    return expr; // Return the final expr (could be primary, CallExpr, GetExpr)
  }

  /// Parses the raw content of an f-string literal into a list of parts.
  /// Parts are either LiteralExpr (for string segments) or parsed expression AST nodes.
  List<FStringPart> _parseFStringContent(Token fstringToken) {
    String content = fstringToken.literal as String;
    List<FStringPart> parts = [];
    StringBuffer currentLiteral = StringBuffer();
    int i = 0;
    final int length = content.length;
    while (i < length) {
      if (content[i] == '{') {
        if (i + 1 < length && content[i + 1] == '{') {
          // Escaped {{ -> add single { to literal
          currentLiteral.write('{');
          i += 2; // Skip both {{
        } else {
          // Start of an expression
          if (currentLiteral.isNotEmpty) {
            parts.add(FStringLiteralPart(currentLiteral.toString()));
            currentLiteral.clear();
          }
          i++; // Move past the opening {

          // --- separate expression and optional format spec ---
          int exprStart = i;
          int braceLevel = 1;
          int colonPos = -1;
          int exprEnd = -1;
          while (i < length) {
            if (content[i] == '{') {
              braceLevel++;
            } else if (content[i] == '}') {
              braceLevel--;
              if (braceLevel == 0) {
                exprEnd = i;
                break;
              }
            } else if (content[i] == ':' && braceLevel == 1) {
              // Found colon for format specifier at the top level of this expression
              if (colonPos == -1) { // save only first colon on top level
                  colonPos = i;
              }
            } else if (content[i] == '\'' || content[i] == '"') {
              String quote = content[i];
              i++;
              while(i < length && content[i] != quote) {
                if (content[i] == '\\' && i + 1 < length) i++;
                i++;
              }
              if (i >= length) throw ParseError(fstringToken, "Unterminated string inside f-string expression.");
            }
            i++;
          } // End of the inner loop looking for '}'

          if (exprEnd == -1) {
            throw ParseError(fstringToken, "Unterminated expression in f-string (missing '}')");
          }

          // --- Extract expression and format spec ---
          String exprString;
          String? formatSpec;
          if (colonPos != -1) {
            exprString = content.substring(exprStart, colonPos).trim();
            formatSpec = content.substring(colonPos + 1, exprEnd);
          } else {
            exprString = content.substring(exprStart, exprEnd).trim();
            // formatSpec remains null
          }

          if (exprString.isEmpty) {
            throw ParseError(fstringToken, "Empty expression sequence in f-string is not allowed.");
          }

          // --- parse expression ---
          Expr parsedExpr;
          try {
            Lexer exprLexer = Lexer(exprString);
            List<Token> exprTokens = exprLexer.scanTokens();
              if (exprTokens.isEmpty || exprTokens.first.type == TokenType.EOF) {
                throw ParseError(fstringToken, "Empty expression in f-string.");
              }
            Parser exprParser = Parser(exprTokens);
            parsedExpr = exprParser.expression();
            if (exprParser.current < exprTokens.length -1) {
             Token unexpectedToken = exprTokens[exprParser.current];
             throw ParseError(unexpectedToken,
               "Unexpected token inside f-string expression near '${unexpectedToken.lexeme}' after parsing expression '$exprString'. Expected end of expression.");
            }
          } catch(e) {
            throw ParseError(fstringToken, "Parser error within f-string expression: '$exprString' -> $e");
          }

          parts.add(FStringExpressionPart(parsedExpr, formatSpec));
          i = exprEnd + 1; // Move past the closing }
        }
      } else if (content[i] == '}') {
        if (i + 1 < length && content[i + 1] == '}') {
          currentLiteral.write('}');
          i += 2;
          continue;
        } else {
          throw ParseError(fstringToken, "f-string: single '}' is not allowed");
        }
      } else {
        // Regular character
        currentLiteral.write(content[i]);
        i++;
      }
    } // End of outer while loop

    if (currentLiteral.isNotEmpty) {
      parts.add(FStringLiteralPart(currentLiteral.toString()));
    }
    return parts;
  }

  /// Finishes parsing a function call after the opening parenthesis '(' has been matched.
  /// Parses the argument list (positional and keyword).
  /// arguments ::= argument ( "," argument )* ;
  /// argument  ::= expression | IDENTIFIER "=" expression ; // Add *expr, **expr later?
  Expr finishCall(Expr callee) {
    List<Argument> arguments = []; // NEW list type
    bool positionalAllowed =
        true; // Allow positional args until a keyword arg is seen

    if (!check(TokenType.RIGHT_PAREN)) {
      do {
        if (arguments.length >= 255) {
          error(peek(), "Cannot have more than 255 arguments.");
        }
        // Lookahead for keyword argument: IDENTIFIER =
        if (check(TokenType.IDENTIFIER) &&
            peekNextToken().type == TokenType.EQUAL) {
          Token name = consume(TokenType.IDENTIFIER, "Expect argument name.");
          consume(TokenType.EQUAL, "Expect '=' after keyword argument name.");
          Expr value = expression();
          arguments.add(KeywordArgument(name, value));
          positionalAllowed = false;  // No positionals after the first keyword
        } else {
          // Positional argument
          if (!positionalAllowed) {
            error(peek(), "Positional argument follows keyword argument.");
          }
          Expr value = expression();
          arguments.add(PositionalArgument(value));
        }
      } while (match([TokenType.COMMA]));
    }
    Token paren = consume(TokenType.RIGHT_PAREN, "Expect ')' after arguments.");
    return CallExpr(callee, paren, arguments); // Pass the new list
  }

  /// Finishes parsing an indexing operation after the opening bracket '[' has been matched.
  /// index ::= "[" expression "]" ;
  Expr finishIndex(Expr object) {
    Token bracket = previous(); // The '[' token
    Expr index = expression();
    consume(TokenType.RIGHT_BRACKET, "Expect ']' after index.");
    return IndexGetExpr(object, bracket, index);
  }

  /// Parses the highest-precedence expressions: literals, variables, parenthesized expressions,
  /// list literals, and dictionary literals.
  /// primary ::= NUMBER | STRING | "True" | "False" | "None"
  ///           | IDENTIFIER
  ///           | "(" expression ")"
  ///           | "[" (expression ("," expression)*)? "]"
  ///           | "{" (pair ("," pair)*)? "}" ;
  /// pair    ::= expression ":" expression ;
  Expr primary() {
    if (match([TokenType.FALSE])) return LiteralExpr(false);
    if (match([TokenType.TRUE])) return LiteralExpr(true);
    if (match([TokenType.NONE])) return LiteralExpr(null);

    if (match([TokenType.NUMBER, TokenType.STRING])) {
      return LiteralExpr(previous().literal);
    }
    if (match([TokenType.SUPER])) {
        Token keyword = previous();
        consume(TokenType.LEFT_PAREN, "Expect '(' after 'super'.");
        consume(TokenType.RIGHT_PAREN, "Expect ')' after 'super('.");
        consume(TokenType.DOT, "Expect '.' after 'super'.");
        Token method = consume(TokenType.IDENTIFIER, "Expect superclass method name.");
        return SuperExpr(keyword, method);
    }
    if (match([TokenType.LEFT_BRACKET])) {
      // List literal [ ... ]
      Token bracket = previous();
      List<Expr> elements = [];
      if (!check(TokenType.RIGHT_BRACKET)) {
        do {
          if (check(TokenType.RIGHT_BRACKET)) break; // Allow trailing comma: [1, 2, ]
          elements.add(expression());
        } while (match([TokenType.COMMA]));
      }
      consume(TokenType.RIGHT_BRACKET, "Expect ']' after list elements.");
      return ListLiteralExpr(bracket, elements);
    }

    if (match([TokenType.LEFT_BRACE])) {
      Token brace = previous();
      List<Expr> keys = [];  // Temp list for potential keys OR set elements
      List<Expr> values = []; // Temp list for potential values
      if (!check(TokenType.RIGHT_BRACE)) {
        do {
          if (check(TokenType.RIGHT_BRACE)) break;
          Expr keyOrElement  = expression();
          if (match([TokenType.COLON])) {
            // It's a dictionary entry
            if (values.length != keys.length) {
              // This means we previously parsed a set element, now mixing with dict entry
              throw error(previous(), "Cannot mix set elements and dict key-value pairs in the same literal.");
            }
            Expr value = expression();
            keys.add(keyOrElement);
            values.add(value);
          } else {
            // It's potentially a set element
            if (values.isNotEmpty) {
              // This means we previously parsed dict entries, now mixing with set element
              throw error(peek(), "Cannot mix set elements and dict key-value pairs in the same literal.");
              // Note: Check based on peek(), as no COLON was matched
            }
            keys.add(keyOrElement); // Store as potential set element
          }
        } while (match([TokenType.COMMA]));
      }
      consume(TokenType.RIGHT_BRACE, "Expect '}' after set elements or dictionary entries.");
      if (values.isNotEmpty) {
        // If we collected values, it was a dictionary
        if (keys.length != values.length) {
            // Should not happen due to checks above, but safety first
            throw error(brace, "Internal parser error: Mismatched keys/values in dictionary literal.");
        }
        return DictLiteralExpr(brace, keys, values);
      } else {
        // If no values were collected, it was a set (or empty dict {})
        if (keys.isEmpty) {
          // It's an empty dict {}
          return DictLiteralExpr(brace, [], []);
        } else {
          // It's a set literal
          return SetLiteralExpr(brace, keys); // keys list now contains set elements
        }
      }
    }

    // --- Tuple/Grouping Parentheses Handling ---
    if (match([TokenType.LEFT_PAREN])) {
      Token paren = previous();
      // Case 1: Empty tuple ()
      if (check(TokenType.RIGHT_PAREN)) {
        consume(TokenType.RIGHT_PAREN, "Expect ')' after '('.");
        return TupleLiteralExpr(paren, []); // Empty tuple
      }
      Expr expr = expression(); // Parse the first expression
      // Case 2: Single element tuple (expr,)
      if (match([TokenType.COMMA])) {
        List<Expr> elements = [expr];
        // Parse remaining elements if any
        while (!check(TokenType.RIGHT_PAREN) && !isAtEnd()) {
          // Allow trailing comma: (a, b, )
          if (peek().type == TokenType.RIGHT_PAREN) break;
          elements.add(expression());
          if (!match([TokenType.COMMA])) {
            // If no comma follows, the next MUST be ')'
            break;
          }
        }
        consume(TokenType.RIGHT_PAREN, "Expect ')' after tuple elements.");
        return TupleLiteralExpr(paren, elements);
      }
      // Case 3: Grouping expression (expr)
      else {
        consume(TokenType.RIGHT_PAREN, "Expect ')' after expression.");
        return GroupingExpr(expr);
      }
    } 

    if (match([TokenType.IDENTIFIER])) {
      // Check if it's a built-in function name we didn't make a keyword?
      // Example: If RANGE wasn't a keyword.
      // Token nameToken = previous();
      // if (nameToken.lexeme == "range") { /* special handling? */ }
      // For now, all identifiers are variables unless called.
      return VariableExpr(previous());
    }

    // --- F-String Handling ---
    if (match([TokenType.F_STRING])) {
      Token fstringToken = previous();
      try {
        List<FStringPart> parts = _parseFStringContent(fstringToken);
        return FStringExpr(fstringToken, parts);
      } on ParseError catch(e) {
        // Re-throw with better context if possible, or just throw
        throw error(fstringToken, "Invalid f-string syntax: ${e.message}");
      } catch (e) {
        throw error(fstringToken, "Error parsing f-string content: $e");
      }
    }
    
    // Error: Expect expression
    print("throw Error");
    throw error(peek(), "Expect expression.");
  }

  // --- Helper Methods ---

  /// Checks if the current token's type is one of the given [types].
  /// If a match is found, consumes the token ([advance]s) and returns true.
  /// Otherwise, returns false without consuming the token.
  bool match(List<TokenType> types) {
    for (TokenType type in types) {
      if (check(type)) {
        advance();
        return true;
      }
    }
    return false;
  }

  /// Checks if the current token is of the expected [type].
  /// If yes, consumes and returns the token.
  /// If no, throws a [ParseError] with the given [message].
  Token consume(TokenType type, String message) {
    if (check(type)) return advance();
    throw error(peek(), message);
  }

  /// Checks if the current token's type matches the given [type] without consuming it.
  /// Returns false if at the end of the token stream.
  bool check(TokenType type) {
    if (isAtEnd()) return false;
    return peek().type == type;
  }

  /// Consumes and returns the current token, advancing the parser state.
  /// Returns the previous token (the one just consumed).
  Token advance() {
    if (!isAtEnd()) current++;
    return previous();
  }

  /// Returns true if all tokens have been consumed (i.e., current token is EOF).
  bool isAtEnd() {
    return peek().type == TokenType.EOF;
  }

  Token peek() {
    // Bounds check might be needed if current can exceed length due to errors
    if (current >= tokens.length) return tokens.last; // Should be EOF
    return tokens[current];
  }

  /// Returns the token *after* the current one, without consuming anything. Useful for lookahead.
  Token peekNextToken() {
    if (current + 1 >= tokens.length) return tokens.last; // EOF
    return tokens[current + 1];
  }

  /// Returns the current token without consuming it.
  Token previous() {
    if (current == 0) return Token(TokenType.EOF, "", null, 0, 0); // Should not happen in normal flow
    return tokens[current - 1];
  }

  /// Reports a parsing error by creating a [ParseError] associated with the given [token].
  /// It also calls the optional [errorCallback] if provided.
  /// Returns the created [ParseError] object, which should typically be thrown by the caller.
  ParseError error(Token token, String message) {
    // Don't set panic mode globally, handle recovery via synchronize
    // _panicMode = true; // Enter panic mode on error
    // Return the error to be thrown by the caller
    if (errorCallback != null) errorCallback!(message);
    return ParseError(token, message);
  }

  /// Attempts to recover from a parsing error to allow finding subsequent errors.
  ///
  /// It discards tokens until it finds a point where parsing can likely resume,
  /// typically the beginning of a new statement (often indicated by specific keywords
  /// or after a newline). It advances past the erroneous token first.
  void synchronize() {
    if (isAtEnd()) return; // Nothing to synchronize if already at end

    // Advance past the token that caused the error, unless already advanced
    // The error is reported *at* peek(), so advance moves past it.
    if (!isAtEnd()) advance();

    while (!isAtEnd()) {
      // Primary recovery point: End of a statement (often marked by newline in Python)
      if (previous().type == TokenType.NEWLINE) {
        // After a newline, the next token *should* be INDENT, DEDENT, or the start of a new statement.
        // Let the main parsing loop handle the next token.
        return;
      }

      // Look for tokens that are likely to start a new statement or declaration.
      switch (peek().type) {
        case TokenType.DEF:
        case TokenType.IF:
        case TokenType.WHILE:
        case TokenType.FOR:
        case TokenType.RETURN:
        case TokenType.PASS:
        case TokenType.BREAK:
        case TokenType.CONTINUE:
          // These keywords strongly suggest the start of a new statement.
          return; // Stop synchronizing, let the main parse loop try this token.
        default:
          // Keep consuming tokens until a recovery point is found.
          break;
      }
      advance();
    }
  }
}
