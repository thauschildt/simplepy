// ignore_for_file: constant_identifier_names

/// Enumerates all the possible types of [Token]s that the [Lexer] can recognize.
///
/// This includes single and multi-character operators, literals (like numbers and strings),
/// keywords (like `if`, `while`), identifiers, and special control tokens like
/// [TokenType.INDENT], [TokenType.DEDENT], [TokenType.NEWLINE], and [TokenType.EOF].
enum TokenType {
  // Single-character tokens.
  LEFT_PAREN,
  RIGHT_PAREN,
  LEFT_BRACKET,
  RIGHT_BRACKET,
  LEFT_BRACE,
  RIGHT_BRACE,
  COMMA,
  DOT,
  MINUS,
  PLUS,
  SLASH,
  STAR,
  PERCENT,
  COLON,

  // One or two character tokens.
  BANG,
  BANG_EQUAL,
  EQUAL,
  EQUAL_EQUAL,
  GREATER,
  GREATER_EQUAL,
  LESS,
  LESS_EQUAL,
  PLUS_EQUAL,
  MINUS_EQUAL,
  STAR_EQUAL,
  SLASH_EQUAL,
  PERCENT_EQUAL,
  STAR_STAR_EQUAL,
  SLASH_SLASH_EQUAL,
  STAR_STAR,
  SLASH_SLASH,
  AMPERSAND,          // &
  PIPE,               // |
  CARET,              // ^
  TILDE,              // ~
  LEFT_SHIFT,         // <<
  RIGHT_SHIFT,        // >>
  AMPERSAND_EQUAL,    // &=
  PIPE_EQUAL,         // |=
  CARET_EQUAL,        // ^=
  LEFT_SHIFT_EQUAL,   // <<=
  RIGHT_SHIFT_EQUAL,  // >>=

  // Literals.
  IDENTIFIER,
  STRING,
  F_STRING,
  NUMBER,

  // Keywords.
  IF,
  ELIF,
  ELSE,
  WHILE,
  FOR,
  BREAK,
  CONTINUE,
  PASS,
  IN,
  DEF,
  GLOBAL,
  NONLOCAL,
  RETURN,
  TRUE,
  FALSE,
  NONE,
  PRINT,
  RANGE,
  AND,
  OR,
  NOT,
  CLASS, SUPER,
  LAMBDA,
  // Whitespace & Control
  INDENT,
  DEDENT,
  NEWLINE, // NEWLINE is significant in Python
  EOF,
}

/// Represents a single lexical unit identified by the [Lexer].
///
/// Each token has a [type] (see [TokenType]), the raw text [lexeme] from the source,
/// an optional decoded [literal] value (for strings and numbers), and the starting
/// [line] and [column] number in the source code for error reporting.
class Token {
  final TokenType type;
  final String lexeme;
  final Object? literal;
  final int line;
  final int column; // Added column for better error reporting

  Token(this.type, this.lexeme, this.literal, this.line, this.column);

  @override
  String toString() {
    return '$type $lexeme ${literal ?? ""} (L$line:C$column)';
  }
}

/// A lexer (also known as scanner or tokenizer) that breaks down Python subset
/// source code into a sequence of [Token] objects.
///
/// It recognizes keywords, identifiers, operators, literals, and
/// handles Python's significant whitespace to produce [TokenType.INDENT] and
/// [TokenType.DEDENT] tokens. It also ignores comments and handles newlines.
class Lexer {
  /// The source code string being tokenized.
  final String source;

  /// The list of tokens generated by the lexer. Populated by [scanTokens].
  final List<Token> tokens = [];

  /// The starting position of the current lexeme being scanned in the [source].
  int start = 0;

  /// The current position (index) in the [source] string.
  int current = 0;

  /// The current line number in the [source] (1-based).
  int line = 1;

  /// The starting index of the current line in the [source] string, used for column calculation.
  int lineStart = 0;

  /// A stack holding the indentation levels (number of leading spaces).
  /// Used to detect [TokenType.INDENT] and [TokenType.DEDENT]. Starts with 0.
  List<int> indentStack = [0];

  int _openParens = 0; // counter for opened parentheses ((), [], {})

  /// A map of reserved words to their corresponding [TokenType].
  static final Map<String, TokenType> keywords = {
    'if': TokenType.IF,
    'elif': TokenType.ELIF,
    'else': TokenType.ELSE,
    'while': TokenType.WHILE,
    'for': TokenType.FOR,
    'break': TokenType.BREAK,
    'continue': TokenType.CONTINUE,
    'in': TokenType.IN,
    'def': TokenType.DEF,
    'global': TokenType.GLOBAL,
    'nonlocal': TokenType.NONLOCAL,
    'pass': TokenType.PASS,
    'return': TokenType.RETURN,
    'True': TokenType.TRUE,
    'False': TokenType.FALSE,
    'None': TokenType.NONE,
    //'print': TokenType.PRINT,
    //'range': TokenType.RANGE,
    'and': TokenType.AND,
    'or': TokenType.OR,
    'not': TokenType.NOT,
    'class': TokenType.CLASS,
    'super': TokenType.SUPER,
    'lambda': TokenType.LAMBDA,
  };

  Lexer(this.source);

  /// Scans the entire [source] string and returns a list of [Token]s.
  ///
  /// This method drives the tokenization process. It handles initial indentation,
  /// iterates through the code character by character calling internal scanning
  /// methods for individual tokens, manages the indentation stack ([TokenType.INDENT]/[TokenType.DEDENT]),
  /// ensures necessary dedents are added at the end of the file, and finally appends
  /// an [TokenType.EOF] token to mark the end.
  ///
  /// Throws a [LexerError] if invalid syntax (e.g., unexpected characters,
  /// unterminated strings, inconsistent indentation) is found.
  List<Token> scanTokens() {
    handleIndentation(); // Handle potential initial indentation

    while (!isAtEnd()) {
      start = current;
      scanToken();
    }

    // Handle any remaining dedents at the end of the file
    while (indentStack.length > 1) {
      indentStack.removeLast();
      tokens.add(
        Token(TokenType.DEDENT, '', null, line, 1),
      ); // DEDENT has no lexeme
    }

    tokens.add(Token(TokenType.EOF, "", null, line, currentColumn() + 1));
    return tokens;
  }

  int currentColumn() => current - lineStart + 1;

  /// Scans the next single token from the source code.
  ///
  /// This is the main dispatch method that determines the type of the next token
  /// based on the current character and potentially subsequent characters.
  /// It calls specific helper methods (like [string], [number], [identifier])
  /// or [addToken] directly for simpler tokens. It also handles comments and whitespace.
  void scanToken() {

    String c = advance();
    switch (c) {
      case '(': _openParens++; addToken(TokenType.LEFT_PAREN); break;
      case ')': _openParens--; addToken(TokenType.RIGHT_PAREN); break;
      case '[': _openParens++; addToken(TokenType.LEFT_BRACKET); break;
      case ']': _openParens--; addToken(TokenType.RIGHT_BRACKET); break;
      case '{': _openParens++; addToken(TokenType.LEFT_BRACE); break;
      case '}': _openParens--; addToken(TokenType.RIGHT_BRACE); break;
      case ',': addToken(TokenType.COMMA); break;
      case '.': if (isDigit(peek())) {
          current--; // Go back to the '.'
          number(); // number() will now see '.' at source[start]
        } else {
          // Just a regular DOT token
          addToken(TokenType.DOT);
        }
        break;
      case '-': addToken(match('=') ? TokenType.MINUS_EQUAL : TokenType.MINUS); break;
      case '+': addToken(match('=') ? TokenType.PLUS_EQUAL : TokenType.PLUS); break;
      case '*':
        if (match('*')) {
          // Check for second '*'
          if (match('=')) {
            // Check for '=' after '**'
            addToken(TokenType.STAR_STAR_EQUAL); // **=
          } else {
            addToken(TokenType.STAR_STAR); // **
          }
        } else if (match('=')) {
          // Check for '=' after '*'
          addToken(TokenType.STAR_EQUAL); // *=
        } else {
          addToken(TokenType.STAR); // *
        }
        break;
      case '/':
        if (match('/')) {
          if (match('=')) {
            addToken(TokenType.SLASH_SLASH_EQUAL);
          } else {
            addToken(TokenType.SLASH_SLASH);
          }
        } else if (match('=')) {
          addToken(TokenType.SLASH_EQUAL);
        } else {
          addToken(TokenType.SLASH);
        }
        break;
      case '%':
        addToken(match('=') ? TokenType.PERCENT_EQUAL : TokenType.PERCENT);
        break;
      case ':':
        addToken(TokenType.COLON);
        break;
      case '!':
        addToken(match('=') ? TokenType.BANG_EQUAL : TokenType.BANG);
        break; // BANG might not be used in simple Python
      case '=':
        addToken(match('=') ? TokenType.EQUAL_EQUAL : TokenType.EQUAL);
        break;
      case '<':
        if (match('<')) {
          addToken(match('=') ? TokenType.LEFT_SHIFT_EQUAL : TokenType.LEFT_SHIFT); // << or <<=
        } else { // < oder <=
          addToken(match('=') ? TokenType.LESS_EQUAL : TokenType.LESS);
        }
        break;
      case '>':
        if (match('>')) {
          addToken(match('=') ? TokenType.RIGHT_SHIFT_EQUAL : TokenType.RIGHT_SHIFT); // >> or >>=
        } else {
          addToken(match('=') ? TokenType.GREATER_EQUAL : TokenType.GREATER);
        }
        break;
      case '&': addToken(match('=') ? TokenType.AMPERSAND_EQUAL : TokenType.AMPERSAND); break;
      case '|': addToken(match('=') ? TokenType.PIPE_EQUAL : TokenType.PIPE); break;
      case '^': addToken(match('=') ? TokenType.CARET_EQUAL : TokenType.CARET); break;
      case '~': addToken(TokenType.TILDE); break;
      
      case '#': // Comment
        while (peek() != '\n' && !isAtEnd()) { advance(); }
        // Don't add a token for comments, but handle potential newline/indentation
        // Check if the comment was the only thing on the line before triggering indentation handling
        if (current == start + 1 &&
            (current > 1 && source[current - 2] == '\n')) {
          handleIndentation(); // Handle indentation if comment starts the line
        }
        break;

      case ' ':
      case '\r':
      case '\t':
        // Ignore other whitespace unless it's at the start of a line (handled by handleIndentation)
        break;
      case '\n':
        line++;
        lineStart = current;
        if (_openParens == 0) {
          handleIndentation(); // Check indentation on new lines
        }
        break;
      case '"':
      case "'":
        string(c);
        break;
      // --- Potential F-string ---
      case 'f':
      case 'F':
        // Lookahead: is the next character a quotation mark?
        if (peek() == '"' || peek() == "'") {
          String quoteType = peek();
          advance();
          fstring(quoteType);
        } else {
          // Just an identifier. Go back to include the 'f' in the identifier name
          current--;
          identifier();
        }
        break;
      default:
        if (isDigit(c)) {
          // Backtrack because number() expects to start at the first digit
          current--;
          number();
        } else if (isAlpha(c)) {
          current--; // Backtrack for identifier()
          identifier();
        } else {
          throw LexerError(line, currentColumn() - 1, "Unexpected character: '$c'");
        }
        break;
    }
  }

  /// Checks and handles indentation changes at the beginning of a line.
  ///
  /// This method is called after a newline or at the start of the file.
  /// It calculates the leading whitespace, compares it to the previous indentation
  /// level stored in [indentStack], and adds [TokenType.INDENT] or [TokenType.DEDENT]
  /// tokens to the [tokens] list as necessary. It also handles blank lines and
  /// lines containing only comments correctly, ensuring they don't affect indentation.
  /// May add implicit [TokenType.NEWLINE] tokens before INDENT/DEDENT if needed.
  /// Throws [LexerError] for inconsistent indentation.
  void handleIndentation() {
    // Only handle indentation after a newline or at the very beginning
    bool atStart = tokens.isEmpty;
    bool afterNewline = !atStart && current > 0 && source[current - 1] == '\n';
    if (!atStart && !afterNewline) return; // Don't check mid-line whitespace

    int currentIndent = 0;
    int col = 1;
    int tempCurrent =
        current; // Use temp cursor to calculate indent without consuming chars yet
    while (tempCurrent < source.length && source[tempCurrent] == ' ') {
      tempCurrent++;
      currentIndent++;
      col++;
    }

    // Check for empty lines or lines with only comments AFTER the indent calculation point
    int checkPos = tempCurrent;
    while (checkPos < source.length &&
        (source[checkPos] == '\t' ||
            source[checkPos] == '\r' ||
            source[checkPos] == ' ')) {
      checkPos++; // Skip whitespace after potential indent
    }

    bool isEmptyOrCommentLine = false;
    if (checkPos == source.length ||
        source[checkPos] == '\n' ||
        source[checkPos] == '#') {
      isEmptyOrCommentLine = true;
    }

    // If it's an empty or comment-only line, skip processing indent/dedent tokens
    // but consume the whitespace and potentially the comment and newline
    if (isEmptyOrCommentLine) {
      current = tempCurrent; // Consume the leading spaces we counted
      // Skip remaining whitespace/comment on the line
      while (peek() != '\n' && !isAtEnd()) {
        if (peek() == '#') {
          while (peek() != '\n' && !isAtEnd()) { advance(); }
          break; // Exit inner comment loop once newline or EOF is hit
        } else if (peek() == ' ' || peek() == '\t' || peek() == '\r') {
          advance();
        } else {
          // Should not happen if isEmptyOrCommentLine logic is correct, but safety break
          break;
        }
      }
      // If we landed on a newline, consume it and potentially check next line
      if (peek() == '\n') {
        advance(); // Consume the newline
        line++;
        lineStart = current;
        handleIndentation(); // Recursively handle next line if also empty/comment
      }
      return; // Don't generate INDENT/DEDENT/NEWLINE for this line
    }

    // --- If it's a significant line, process indentation ---
    current = tempCurrent; // Consume the leading spaces we counted

    // Add implicit NEWLINE before INDENT/DEDENT if the previous token wasn't one
    // (and we are not at the start or immediately after another indent/dedent)
    if (tokens.isNotEmpty &&
        tokens.last.type != TokenType.NEWLINE &&
        tokens.last.type != TokenType.INDENT &&
        tokens.last.type != TokenType.DEDENT) {
      // Add newline from the *previous* line end
      tokens.add(
        Token(
          TokenType.NEWLINE,
          '\\n',
          null,
          line - 1,
          tokens.last.column + tokens.last.lexeme.length,
        ),
      );
    }

    int lastIndent = indentStack.last;

    if (currentIndent > lastIndent) {
      indentStack.add(currentIndent);
      tokens.add(
        Token(TokenType.INDENT, '', null, line, 1),
      ); // Indent starts at col 1
    } else if (currentIndent < lastIndent) {
      while (indentStack.last > currentIndent) {
        indentStack.removeLast();
        // Check if stack becomes empty (error) or goes below zero (error)
        if (indentStack.isEmpty) {
          throw LexerError(
            line,
            col,
            "Indentation error: Dedent does not match any outer indentation level.",
          );
        }
        tokens.add(Token(TokenType.DEDENT, '', null, line, 1));
      }
      // After dedenting, the current level must match the stack top
      if (indentStack.last != currentIndent) {
        throw LexerError(
          line,
          col,
          "Indentation error: Inconsistent dedent level.",
        );
      }
    }
    // No token needed if indentation level is the same

    start =
        current; // Adjust start for the actual token after indentation whitespace
  }

  /// Scans an identifier or a keyword.
  /// Identifiers start with a letter or underscore, followed by letters, digits, or underscores.
  /// If the scanned identifier matches a reserved word in [keywords], the corresponding
  /// keyword [TokenType] is used; otherwise, [TokenType.IDENTIFIER] is used.
  void identifier() {
    while (isAlphaNumeric(peek())) { advance(); }
    String text = source.substring(start, current);
    TokenType type = keywords[text] ?? TokenType.IDENTIFIER;
    addToken(type);
  }

  /// Scans a number literal (integer or floating-point).
  void number() {
    start = current; // Ensure start is set correctly before advancing
    bool startsWithDot = peek() == '.';
    bool isFloat = startsWithDot;
    bool hasExponent = false;
    bool hasFractionalDigits = false;
    // 1. Consume leading dot if present
    if (startsWithDot) {
      advance(); // Consume '.'
      // Must be followed by digits *or* 'e'/'E' eventually for validity check later
      if (!isDigit(peek()) && peek().toLowerCase() != 'e') {
        // This was just a DOT token
        current = start + 1; // Reset position to only include the dot
        addToken(TokenType.DOT);
        return; // Not a number
      }
    }

    // 2. Consume integer part (if not starting with dot)
    if (!startsWithDot) {
      // --- Handle Prefixed Integers (0x, 0b, 0o) ---
      if (peek() == '0' && current == start && current + 1 < source.length) {
        String nextChar = source[current + 1].toLowerCase();
        if (nextChar == 'x' || nextChar == 'b' || nextChar == 'o') {
          advance(); // Consume '0'
          advance(); // Consume 'x', 'b', or 'o'
          _scanPrefixedInteger(nextChar);
          return; // Prefixed integer handled
        }
        // Fall through for '0.' or '0' followed by other digits (decimal)
      }
      // --- Consume Decimal Integer Part ---
      while (isDigit(peek())) {
        advance();
      }
    }

    // 3. Consume optional fractional part
    //    This runs if we didn't start with a dot AND a dot follows the integer part,
    //    OR if we *did* start with a dot (because we need to consume the digits after it).
    if (peek() == '.') {
        if (startsWithDot) {
            // We already consumed the starting dot. This would be a second dot.
            throw LexerError(line, currentColumn(), "Invalid syntax: multiple decimal points in number.");
        }
        isFloat = true;
        advance(); // Consume '.'
    }
    if (isFloat) { // Consume digits if it's a float (either startsWithDot or dotSeenAfterInteger)
      int fractionStart = current;
      while (isDigit(peek())) {
        advance();
      }
      if (current > fractionStart) {
        hasFractionalDigits = true;
      }
      // If startsWithDot is true, we MUST have found some fractional digits OR an exponent later
      if (startsWithDot && !hasFractionalDigits && peek().toLowerCase() != 'e') {
        // Example: "." followed by non-digit, non-'e'
        throw LexerError(line, start - lineStart + 1, "Invalid number format: lone decimal point.");
      }
    }

    // 4. Consume optional exponent part
    if (peek().toLowerCase() == 'e') {
      // Ensure something came before 'e'
      if (current == start || (startsWithDot && !hasFractionalDigits)) {
        // Handles cases like "e5" or ".e5"
        throw LexerError(line, start - lineStart + 1,
          "Invalid number format: exponent must follow digits or decimal point with digits.");
      }
      isFloat = true;
      hasExponent = true;
      advance(); // Consume 'e' or 'E'
      if (peek() == '+' || peek() == '-') { advance(); } // Optional sign
      int exponentStart = current;
      while (isDigit(peek())) { advance(); }
      if (current == exponentStart) {
        throw LexerError(line, currentColumn(), "Invalid scientific notation: exponent lacks digits.");
      }
    }
    
    // --- Parse and validate the Literal Value ---
    String numberString = source.substring(start, current);

    // Python allows "1." or ".5" but not just "."
    // Our logic now prevents just "." from reaching here.
    // Validate ".e5" - should fail because no digits after initial dot before 'e'
    if (startsWithDot && !hasFractionalDigits && !hasExponent) {
      // This means we only parsed "." which should have been handled earlier.
      // This code path likely indicates an error in the logic above.
      // However, let's treat it as just a DOT token if it occurs.
      current = start + 1; // Reset current to only include the dot
      addToken(TokenType.DOT);
      return;
    }

    Object literalValue;

    try {
      // If it has '.', 'e', or started with '.', treat as float
      if (isFloat) {
        literalValue = double.parse(numberString);
      } else {
        literalValue = int.parse(numberString);
      }
    } catch (e) {
      String formatType = isFloat ? "floating-point" : "integer";
      throw LexerError(line, start - lineStart + 1, "Invalid $formatType number format: '$numberString'");
    }
    addToken(TokenType.NUMBER, literalValue);
  }

  /// Scans the digits of an integer literal after a base prefix (0x, 0b, 0o) has been identified.
  ///
  /// [prefix] should be the lowercase character 'x', 'b', or 'o'.
  /// Parses the digits according to the specified base and adds a [TokenType.NUMBER] token.
  /// Throws [LexerError] if no valid digits follow the prefix or if parsing fails.
  void _scanPrefixedInteger(String prefix) {
    int radix;
    bool Function(String) isValidDigit;
    String baseName;

    switch (prefix) {
      case 'x':
        radix = 16;
        isValidDigit = isHexDigit;
        baseName = "hexadecimal";
        break;
      case 'b':
        radix = 2;
        isValidDigit = isBinaryDigit;
        baseName = "binary";
        break;
      case 'o':
        radix = 8;
        isValidDigit = isOctalDigit;
        baseName = "octal";
        break;
      default:
        // This should not be reachable due to checks in number()
        throw StateError('Internal error: Invalid prefix "$prefix" passed to _scanPrefixedInteger.');
    }
    int digitStart = current; // Position after the prefix character (e.g., after 'x')
    // Consume all valid digits for the given base
    while (isValidDigit(peek())) {
      advance();
    }

    // Check if any digits were actually found after the prefix
    if (current == digitStart) {
      // Error: Prefix not followed by any digits (e.g., "0x", "0b")
      throw LexerError(line, start - lineStart + 1, // Error starts at '0'
          "Invalid $baseName literal: Missing digits after '0$prefix'.");
    }

    // Extract the substring containing only the digits (after the prefix)
    String digits = source.substring(digitStart, current);

    try {
      // Parse the digits using the determined radix
      int value = int.parse(digits, radix: radix);
      addToken(TokenType.NUMBER, value);
    } catch (e) {
      // This catch might be redundant if digit checks are robust, but acts as a safeguard.
      throw LexerError(
        line,
        start - lineStart + 1, // Error relates to the whole number structure
        "Invalid $baseName literal format for '0$prefix': '$digits'",
      );
    }
  }

  /// Scans a string literal enclosed in single (') or double (") quotes.
  /// Handles unterminated strings by throwing a [LexerError].
  /// [quoteType] is the opening quote character (' or ").
  /// TODO: Implement handling of escape sequences (e.g., \n, \", \\).
  void string(String quoteType) {
    int startLine = line;
    int startCol = currentColumn();
    while (peek() != quoteType && !isAtEnd()) {
      if (peek() == '\n') {
        line++;
        lineStart = current + 1; // Next char starts new line
      }
      advance();
    }

    if (isAtEnd()) {
      throw LexerError(startLine, startCol, "Unterminated string.");
    }

    // The closing quote.
    advance();

    // Trim the surrounding quotes.
    String value = source.substring(start + 1, current - 1);
    String processedValue = _processEscapes(value);
    addToken(TokenType.STRING, processedValue);
  }

  /// Scans an f-string literal. Finds closing quote, handles basic escapes, but preserves content.
  void fstring(String quoteType) {  
    int startLine = line;
    // Start column should be the 'f', which is source[start-2]
    int startCol = (start -0) - lineStart + 1;
    // current position is already AFTER the opening quote here
    while (peek() != quoteType && !isAtEnd()) {
      // Handle escapes within f-string, they affect finding the end quote
      if (peek() == '\\' && current + 1 < source.length) {
        advance(); // Consume backslash
      }
      if (peek() == '\n') {
        line++;
        lineStart = current + 1;
      }
      advance(); // Consume character
    }
    if (isAtEnd()) {
      throw LexerError(startLine, startCol, "Unterminated f-string.");
    }
    // The closing quote.
    advance();
    // Get the raw content between the quotes (Parser will handle {{, }}, and {})
    // start was already adjusted to the 'f' prefix
    String rawContent = source.substring(start + 2, current - 1);
    // NO escape processing here (parser needs raw content)
    // Lexeme includes f prefix and quotes for context
    String lexeme = source.substring(start, current); // Include 'f' prefix
    // Literal value is the raw content for the parser
    tokens.add(Token(TokenType.F_STRING, lexeme, rawContent, startLine, startCol));
  }

  // Helper to process basic string escapes (can be used by string() and by fstring())
  String _processEscapes(String value) {
    // Very basic example, to be expanded
    value = value.replaceAll('\\n', '\n');
    value = value.replaceAll('\\t', '\t');
    value = value.replaceAll('\\\\', '\\');
    value = value.replaceAll('\\\'', '\'');
    value = value.replaceAll('\\"', '"');
    // Add more escapes as needed (\r, \b, \f, \uXXXX, \UXXXXXXXX)
    return value;
  }

  /// Checks if the current character matches [expected]. If so, consumes it and returns true.
  bool match(String expected) {
    if (isAtEnd()) return false;
    if (source[current] != expected) return false;
    current++;
    return true;
  }

  /// Returns the character at the current position without consuming it.
  /// Returns a null character ('\x00') if at the end of the source.
  String peek() {
    if (isAtEnd()) return '\x00'; // Use null character for EOF marker
    return source[current];
  }

  /// Returns the character after the current position without consuming it.
  /// Returns a null character ('\x00') if near the end of the source.
  String peekNext() {
    if (current + 1 >= source.length) return '\x00';
    return source[current + 1];
  }

  /// Checks if character [c] is a letter (a-z, A-Z) or underscore (_).
  bool isAlpha(String c) {
    return (c.compareTo('a') >= 0 && c.compareTo('z') <= 0) ||
        (c.compareTo('A') >= 0 && c.compareTo('Z') <= 0) ||
        c == '_';
  }

  /// Checks if character [c] is a letter, digit, or underscore.
  bool isAlphaNumeric(String c) {
    return isAlpha(c) || isDigit(c);
  }

  /// Checks if character [c] is a digit (0-9).
  bool isDigit(String c) {
    return c.compareTo('0') >= 0 && c.compareTo('9') <= 0;
  }

  /// Checks if character [c] is a binary digit (0 or 1).
  bool isBinaryDigit(String c) {
     return c == '0' || c == '1';
  }

  /// Checks if character [c] is an octal digit (0-7).
  bool isOctalDigit(String c) {
    if (c.isEmpty) return false;
    return c.compareTo('0') >= 0 && c.compareTo('7') <= 0;
  }

  /// Checks if character [c] is a hexadecimal digit (0-9, a-f, A-F).
  bool isHexDigit(String c) {
    if (c.isEmpty) return false;
    return isDigit(c) ||
           (c.compareTo('a') >= 0 && c.compareTo('f') <= 0) ||
           (c.compareTo('A') >= 0 && c.compareTo('F') <= 0);
  }

  /// Returns true if the lexer has reached the end of the [source] string.
  bool isAtEnd() {
    return current >= source.length;
  }

  /// Consumes the character at the current position and returns it, advancing the position.
  String advance() {
    // TODO: Before advancing, check if we are about to cross a newline boundary within the current token scan.
    // This is generally handled after the token is formed or by handleIndentation.
    return source[current++];
  }

  /// Creates a [Token] with the given [type] and optional [literal] value,
  /// using the current [start], [current], [line], and calculated column.
  /// Adds the created token to the [tokens] list.
  void addToken(TokenType type, [Object? literal]) {
    String text = source.substring(start, current);
    tokens.add(Token(type, text, literal, line, start - lineStart + 1));
  }
}

/// A [LexerError] exception thrown when the [Lexer] encounters invalid syntax or characters
/// in the source code.
///
/// It includes the [line] number, [column] number, and a descriptive [message]
/// indicating the nature of the error.
/// 
class LexerError implements Exception {
  final int line;
  final int column;
  final String message;
  LexerError(this.line, this.column, this.message);
  @override
  String toString() => '[line $line, col $column] Lexer Error: $message';
}
