// ignore_for_file: constant_identifier_names

/// Enumerates all the possible types of [Token]s that the [Lexer] can recognize.
///
/// This includes single and multi-character operators, literals (like numbers and strings),
/// keywords (like `if`, `while`), identifiers, and special control tokens like
/// [TokenType.INDENT], [TokenType.DEDENT], [TokenType.NEWLINE], and [TokenType.EOF].
enum TokenType {
  // Single-character tokens.
  LEFT_PAREN,
  RIGHT_PAREN,
  LEFT_BRACKET,
  RIGHT_BRACKET,
  LEFT_BRACE,
  RIGHT_BRACE,
  COMMA,
  DOT,
  MINUS,
  PLUS,
  SLASH,
  STAR,
  PERCENT,
  COLON,

  // One or two character tokens.
  BANG,
  BANG_EQUAL,
  EQUAL,
  EQUAL_EQUAL,
  GREATER,
  GREATER_EQUAL,
  LESS,
  LESS_EQUAL,
  PLUS_EQUAL,
  MINUS_EQUAL,
  STAR_EQUAL,
  SLASH_EQUAL,
  PERCENT_EQUAL,
  STAR_STAR_EQUAL,
  SLASH_SLASH_EQUAL,
  STAR_STAR,
  SLASH_SLASH,
  AMPERSAND,          // &
  PIPE,               // |
  CARET,              // ^
  TILDE,              // ~
  LEFT_SHIFT,         // <<
  RIGHT_SHIFT,        // >>
  AMPERSAND_EQUAL,    // &=
  PIPE_EQUAL,         // |=
  CARET_EQUAL,        // ^=
  LEFT_SHIFT_EQUAL,   // <<=
  RIGHT_SHIFT_EQUAL,  // >>=

  // Literals.
  IDENTIFIER,
  STRING,
  NUMBER,

  // Keywords.
  IF,
  ELIF,
  ELSE,
  WHILE,
  FOR,
  BREAK,
  CONTINUE,
  PASS,
  IN,
  DEF,
  RETURN,
  TRUE,
  FALSE,
  NONE,
  PRINT,
  RANGE,
  AND,
  OR,
  NOT,
  // Whitespace & Control
  INDENT,
  DEDENT,
  NEWLINE, // NEWLINE is significant in Python
  EOF,
}

/// Represents a single lexical unit identified by the [Lexer].
///
/// Each token has a [type] (see [TokenType]), the raw text [lexeme] from the source,
/// an optional decoded [literal] value (for strings and numbers), and the starting
/// [line] and [column] number in the source code for error reporting.
class Token {
  final TokenType type;
  final String lexeme;
  final Object? literal;
  final int line;
  final int column; // Added column for better error reporting

  Token(this.type, this.lexeme, this.literal, this.line, this.column);

  @override
  String toString() {
    return '$type $lexeme ${literal ?? ""} (L$line:C$column)';
  }
}

/// A lexer (also known as scanner or tokenizer) that breaks down Python subset
/// source code into a sequence of [Token] objects.
///
/// It recognizes keywords, identifiers, operators, literals, and
/// handles Python's significant whitespace to produce [TokenType.INDENT] and
/// [TokenType.DEDENT] tokens. It also ignores comments and handles newlines.
class Lexer {
  /// The source code string being tokenized.
  final String source;

  /// The list of tokens generated by the lexer. Populated by [scanTokens].
  final List<Token> tokens = [];

  /// The starting position of the current lexeme being scanned in the [source].
  int start = 0;

  /// The current position (index) in the [source] string.
  int current = 0;

  /// The current line number in the [source] (1-based).
  int line = 1;

  /// The starting index of the current line in the [source] string, used for column calculation.
  int lineStart = 0;

  /// A stack holding the indentation levels (number of leading spaces).
  /// Used to detect [TokenType.INDENT] and [TokenType.DEDENT]. Starts with 0.
  List<int> indentStack = [0];

  /// A map of reserved words to their corresponding [TokenType].
  static final Map<String, TokenType> keywords = {
    'if': TokenType.IF,
    'elif': TokenType.ELIF,
    'else': TokenType.ELSE,
    'while': TokenType.WHILE,
    'for': TokenType.FOR,
    'break': TokenType.BREAK,
    'continue': TokenType.CONTINUE,
    'in': TokenType.IN,
    'def': TokenType.DEF,
    'pass': TokenType.PASS,
    'return': TokenType.RETURN,
    'True': TokenType.TRUE,
    'False': TokenType.FALSE,
    'None': TokenType.NONE,
    //'print': TokenType.PRINT,
    //'range': TokenType.RANGE,
    'and': TokenType.AND,
    'or': TokenType.OR,
    'not': TokenType.NOT,
  };

  Lexer(this.source);

  /// Scans the entire [source] string and returns a list of [Token]s.
  ///
  /// This method drives the tokenization process. It handles initial indentation,
  /// iterates through the code character by character calling internal scanning
  /// methods for individual tokens, manages the indentation stack ([TokenType.INDENT]/[TokenType.DEDENT]),
  /// ensures necessary dedents are added at the end of the file, and finally appends
  /// an [TokenType.EOF] token to mark the end.
  ///
  /// Throws a [LexerError] if invalid syntax (e.g., unexpected characters,
  /// unterminated strings, inconsistent indentation) is found.
  List<Token> scanTokens() {
    handleIndentation(); // Handle potential initial indentation

    while (!isAtEnd()) {
      start = current;
      scanToken();
    }

    // Handle any remaining dedents at the end of the file
    while (indentStack.length > 1) {
      indentStack.removeLast();
      tokens.add(
        Token(TokenType.DEDENT, '', null, line, 1),
      ); // DEDENT has no lexeme
    }

    tokens.add(Token(TokenType.EOF, "", null, line, currentColumn() + 1));
    return tokens;
  }

  int currentColumn() => current - lineStart + 1;

  /// Scans the next single token from the source code.
  ///
  /// This is the main dispatch method that determines the type of the next token
  /// based on the current character and potentially subsequent characters.
  /// It calls specific helper methods (like [string], [number], [identifier])
  /// or [addToken] directly for simpler tokens. It also handles comments and whitespace.
  void scanToken() {
    String c = advance();
    switch (c) {
      case '(': addToken(TokenType.LEFT_PAREN); break;
      case ')': addToken(TokenType.RIGHT_PAREN); break;
      case '[': addToken(TokenType.LEFT_BRACKET); break;
      case ']': addToken(TokenType.RIGHT_BRACKET); break;
      case '{': addToken(TokenType.LEFT_BRACE); break;
      case '}': addToken(TokenType.RIGHT_BRACE); break;
      case ',': addToken(TokenType.COMMA); break;
      case '.': addToken(TokenType.DOT); break; // Might need later
      case '-': addToken(match('=') ? TokenType.MINUS_EQUAL : TokenType.MINUS); break;
      case '+': addToken(match('=') ? TokenType.PLUS_EQUAL : TokenType.PLUS); break;
      case '*':
        if (match('*')) {
          // Check for second '*'
          if (match('=')) {
            // Check for '=' after '**'
            addToken(TokenType.STAR_STAR_EQUAL); // **=
          } else {
            addToken(TokenType.STAR_STAR); // **
          }
        } else if (match('=')) {
          // Check for '=' after '*'
          addToken(TokenType.STAR_EQUAL); // *=
        } else {
          addToken(TokenType.STAR); // *
        }
        break;
      case '/':
        if (match('/')) {
          if (match('=')) {
            addToken(TokenType.SLASH_SLASH_EQUAL);
          } else {
            addToken(TokenType.SLASH_SLASH);
          }
        } else if (match('=')) {
          addToken(TokenType.SLASH_EQUAL);
        } else {
          addToken(TokenType.SLASH);
        }
        break;
      case '%':
        addToken(match('=') ? TokenType.PERCENT_EQUAL : TokenType.PERCENT);
        break;
      case ':':
        addToken(TokenType.COLON);
        break;
      case '!':
        addToken(match('=') ? TokenType.BANG_EQUAL : TokenType.BANG);
        break; // BANG might not be used in simple Python
      case '=':
        addToken(match('=') ? TokenType.EQUAL_EQUAL : TokenType.EQUAL);
        break;
      case '<':
        if (match('<')) {
          addToken(match('=') ? TokenType.LEFT_SHIFT_EQUAL : TokenType.LEFT_SHIFT); // << or <<=
        } else { // < oder <=
          addToken(match('=') ? TokenType.LESS_EQUAL : TokenType.LESS);
        }
        break;
      case '>':
        if (match('>')) {
          addToken(match('=') ? TokenType.RIGHT_SHIFT_EQUAL : TokenType.RIGHT_SHIFT); // >> or >>=
        } else {
          addToken(match('=') ? TokenType.GREATER_EQUAL : TokenType.GREATER);
        }
        break;
      case '&': addToken(match('=') ? TokenType.AMPERSAND_EQUAL : TokenType.AMPERSAND); break;
      case '|': addToken(match('=') ? TokenType.PIPE_EQUAL : TokenType.PIPE); break;
      case '^': addToken(match('=') ? TokenType.CARET_EQUAL : TokenType.CARET); break;
      case '~': addToken(TokenType.TILDE); break;
      
      case '#': // Comment
        while (peek() != '\n' && !isAtEnd()) { advance(); }
        // Don't add a token for comments, but handle potential newline/indentation
        // Check if the comment was the only thing on the line before triggering indentation handling
        if (current == start + 1 &&
            (current > 1 && source[current - 2] == '\n')) {
          handleIndentation(); // Handle indentation if comment starts the line
        }
        break;

      case ' ':
      case '\r':
      case '\t':
        // Ignore other whitespace unless it's at the start of a line (handled by handleIndentation)
        break;

      case '\n':
        line++;
        lineStart = current;
        handleIndentation(); // Check indentation on new lines
        break;

      case '"':
      case "'":
        string(c);
        break;

      default:
        if (isDigit(c)) {
          number();
        } else if (isAlpha(c)) {
          identifier();
        } else {
          throw LexerError(line, currentColumn(), "Unexpected character: '$c'");
        }
        break;
    }
  }

  /// Checks and handles indentation changes at the beginning of a line.
  ///
  /// This method is called after a newline or at the start of the file.
  /// It calculates the leading whitespace, compares it to the previous indentation
  /// level stored in [indentStack], and adds [TokenType.INDENT] or [TokenType.DEDENT]
  /// tokens to the [tokens] list as necessary. It also handles blank lines and
  /// lines containing only comments correctly, ensuring they don't affect indentation.
  /// May add implicit [TokenType.NEWLINE] tokens before INDENT/DEDENT if needed.
  /// Throws [LexerError] for inconsistent indentation.
  void handleIndentation() {
    // Only handle indentation after a newline or at the very beginning
    bool atStart = tokens.isEmpty;
    bool afterNewline = !atStart && current > 0 && source[current - 1] == '\n';
    if (!atStart && !afterNewline) return; // Don't check mid-line whitespace

    int currentIndent = 0;
    int col = 1;
    int tempCurrent =
        current; // Use temp cursor to calculate indent without consuming chars yet
    while (tempCurrent < source.length && source[tempCurrent] == ' ') {
      tempCurrent++;
      currentIndent++;
      col++;
    }

    // Check for empty lines or lines with only comments AFTER the indent calculation point
    int checkPos = tempCurrent;
    while (checkPos < source.length &&
        (source[checkPos] == '\t' ||
            source[checkPos] == '\r' ||
            source[checkPos] == ' ')) {
      checkPos++; // Skip whitespace after potential indent
    }

    bool isEmptyOrCommentLine = false;
    if (checkPos == source.length ||
        source[checkPos] == '\n' ||
        source[checkPos] == '#') {
      isEmptyOrCommentLine = true;
    }

    // If it's an empty or comment-only line, skip processing indent/dedent tokens
    // but consume the whitespace and potentially the comment and newline
    if (isEmptyOrCommentLine) {
      current = tempCurrent; // Consume the leading spaces we counted
      // Skip remaining whitespace/comment on the line
      while (peek() != '\n' && !isAtEnd()) {
        if (peek() == '#') {
          while (peek() != '\n' && !isAtEnd()) { advance(); }
          break; // Exit inner comment loop once newline or EOF is hit
        } else if (peek() == ' ' || peek() == '\t' || peek() == '\r') {
          advance();
        } else {
          // Should not happen if isEmptyOrCommentLine logic is correct, but safety break
          break;
        }
      }
      // If we landed on a newline, consume it and potentially check next line
      if (peek() == '\n') {
        advance(); // Consume the newline
        line++;
        lineStart = current;
        handleIndentation(); // Recursively handle next line if also empty/comment
      }
      return; // Don't generate INDENT/DEDENT/NEWLINE for this line
    }

    // --- If it's a significant line, process indentation ---
    current = tempCurrent; // Consume the leading spaces we counted

    // Add implicit NEWLINE before INDENT/DEDENT if the previous token wasn't one
    // (and we are not at the start or immediately after another indent/dedent)
    if (tokens.isNotEmpty &&
        tokens.last.type != TokenType.NEWLINE &&
        tokens.last.type != TokenType.INDENT &&
        tokens.last.type != TokenType.DEDENT) {
      // Add newline from the *previous* line end
      tokens.add(
        Token(
          TokenType.NEWLINE,
          '\\n',
          null,
          line - 1,
          tokens.last.column + tokens.last.lexeme.length,
        ),
      );
    }

    int lastIndent = indentStack.last;

    if (currentIndent > lastIndent) {
      indentStack.add(currentIndent);
      tokens.add(
        Token(TokenType.INDENT, '', null, line, 1),
      ); // Indent starts at col 1
    } else if (currentIndent < lastIndent) {
      while (indentStack.last > currentIndent) {
        indentStack.removeLast();
        // Check if stack becomes empty (error) or goes below zero (error)
        if (indentStack.isEmpty) {
          throw LexerError(
            line,
            col,
            "Indentation error: Dedent does not match any outer indentation level.",
          );
        }
        tokens.add(Token(TokenType.DEDENT, '', null, line, 1));
      }
      // After dedenting, the current level must match the stack top
      if (indentStack.last != currentIndent) {
        throw LexerError(
          line,
          col,
          "Indentation error: Inconsistent dedent level.",
        );
      }
    }
    // No token needed if indentation level is the same

    start =
        current; // Adjust start for the actual token after indentation whitespace
  }

  /// Scans an identifier or a keyword.
  /// Identifiers start with a letter or underscore, followed by letters, digits, or underscores.
  /// If the scanned identifier matches a reserved word in [keywords], the corresponding
  /// keyword [TokenType] is used; otherwise, [TokenType.IDENTIFIER] is used.
  void identifier() {
    while (isAlphaNumeric(peek())) { advance(); }
    String text = source.substring(start, current);
    TokenType type = keywords[text] ?? TokenType.IDENTIFIER;
    addToken(type);
  }

  /// Scans a number literal (integer or floating-point).
  void number() {
    while (isDigit(peek())) { advance(); }
    // Look for a fractional part.
    if (peek() == '.' && isDigit(peekNext())) {
      // Consume the "."
      advance();
      while (isDigit(peek())) { advance(); }
    }
    String numberString = source.substring(start, current);
    Object literalValue;
    try {
      literalValue =
          numberString.contains('.')
              ? double.parse(numberString)
              : int.parse(numberString);
    } catch (e) {
      throw LexerError(
        line,
        start - lineStart + 1,
        "Invalid number format: '$numberString'",
      );
    }
    addToken(TokenType.NUMBER, literalValue);
  }

  /// Scans a string literal enclosed in single (') or double (") quotes.
  /// Handles unterminated strings by throwing a [LexerError].
  /// [quoteType] is the opening quote character (' or ").
  /// TODO: Implement handling of escape sequences (e.g., \n, \", \\).
  void string(String quoteType) {
    int startLine = line;
    int startCol = currentColumn();
    while (peek() != quoteType && !isAtEnd()) {
      if (peek() == '\n') {
        line++;
        lineStart = current + 1; // Next char starts new line
      }
      // TODO: Handle escape sequences like \" or \\
      advance();
    }

    if (isAtEnd()) {
      throw LexerError(startLine, startCol, "Unterminated string.");
    }

    // The closing quote.
    advance();

    // Trim the surrounding quotes.
    String value = source.substring(start + 1, current - 1);
    // TODO: Process escape sequences in 'value' here
    addToken(TokenType.STRING, value);
  }

  /// Checks if the current character matches [expected]. If so, consumes it and returns true.
  bool match(String expected) {
    if (isAtEnd()) return false;
    if (source[current] != expected) return false;
    current++;
    return true;
  }

  /// Returns the character at the current position without consuming it.
  /// Returns a null character ('\x00') if at the end of the source.
  String peek() {
    if (isAtEnd()) return '\x00'; // Use null character for EOF marker
    return source[current];
  }

  /// Returns the character after the current position without consuming it.
  /// Returns a null character ('\x00') if near the end of the source.
  String peekNext() {
    if (current + 1 >= source.length) return '\x00';
    return source[current + 1];
  }

  /// Checks if character [c] is a letter (a-z, A-Z) or underscore (_).
  bool isAlpha(String c) {
    return (c.compareTo('a') >= 0 && c.compareTo('z') <= 0) ||
        (c.compareTo('A') >= 0 && c.compareTo('Z') <= 0) ||
        c == '_';
  }

  /// Checks if character [c] is a letter, digit, or underscore.
  bool isAlphaNumeric(String c) {
    return isAlpha(c) || isDigit(c);
  }

  /// Checks if character [c] is a digit (0-9).
  bool isDigit(String c) {
    return c.compareTo('0') >= 0 && c.compareTo('9') <= 0;
  }

  /// Returns true if the lexer has reached the end of the [source] string.
  bool isAtEnd() {
    return current >= source.length;
  }

  /// Consumes the character at the current position and returns it, advancing the position.
  String advance() {
    // TODO: Before advancing, check if we are about to cross a newline boundary within the current token scan.
    // This is generally handled after the token is formed or by handleIndentation.
    return source[current++];
  }

  /// Creates a [Token] with the given [type] and optional [literal] value,
  /// using the current [start], [current], [line], and calculated column.
  /// Adds the created token to the [tokens] list.
  void addToken(TokenType type, [Object? literal]) {
    String text = source.substring(start, current);
    tokens.add(Token(type, text, literal, line, start - lineStart + 1));
  }
}

/// A [LexerError] exception thrown when the [Lexer] encounters invalid syntax or characters
/// in the source code.
///
/// It includes the [line] number, [column] number, and a descriptive [message]
/// indicating the nature of the error.
/// 
class LexerError implements Exception {
  final int line;
  final int column;
  final String message;
  LexerError(this.line, this.column, this.message);
  @override
  String toString() => '[line $line, col $column] Lexer Error: $message';
}
